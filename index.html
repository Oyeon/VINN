<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-104480971-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-104480971-1');
  </script>
  <script type="text/javascript">
<!--
    function toggle_visibility(id) {
       var e = document.getElementById(id);
       // if(e.style.display == 'block')
       //    e.style.display = 'none';
       // else
       //    e.style.display = 'block';
        if (e.style.display == 'none')
           e.style.display = 'inline';
       else
           e.style.display = 'none';
    }
//-->
</script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  

  <title>The Surprising Effectiveness of Representation Learning for Visual Imitation</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="paper_stylesheet.css">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name class="paper_title">The Surprising Effectiveness of Representation Learning for Visual Imitation</name>
              </p>
              
              <p></p>
                <br>
                <br>

              <!-- Authors and affiliations table  -->
              <table align=center width=540px cellpadding=0 cellspacing=0>
                  <tr>
                      <td align=center width=180px>
                      <center><span style="font-size:15px"><a href="" target="_blank" class="authors" style="color:black">Jyothish Pari</a></span></center></td>
                      <td align=center width=180px>
                      <center><span  ><a href="" target="_blank" class="authors" style="color:black"></a>Mahi Shafiullah </span></center></td>
                      <td align=center width=180px>
                      <center><span  ><a href="" target="_blank" class="authors" style="color:black">Sridhar Arunachalam</a></span></center></td>
                      <td align=center width=180px>
                      <center><span class="authors"><a href="" target="_blank" class="authors" style="color:black">Lerrel Pinto</a></span></center></td>
                  <tr/>
                  <tr>
                      <td align=center width=180px>
                      <center><span class="affiliations">NYU</span></center></td>
                        <td align=center width=180px>
                      <center><span class="affiliations">NYU</span></center></td>
                        <td align=center width=180px>
                      <center><span class="affiliations">NYU</span></center></td>
                        <td align=center width=180px>
                      <center><span class="affiliations">NYU</span></center></td>

                  <tr/>
               
        </table>
      </td> 
    </tr></tbody>
  </table>

  <table align=center width=540px cellpadding=0 cellspacing=0>
      <tr align=center>
        <td align=center width=180px>
           <!-- <a href="https://arxiv.org/abs/2107.09046" class="smol">Paper |</a> -->
           <!-- <a href="https://github.com/sarahisyoung/Playful-Interactions-for-Representation-Learning" class="smol">Code |</a> -->
          <a href="https://www.dropbox.com/sh/4wcq3vwwgi7gggi/AADKHIRP3O5wsXpSoBpOKwYwa?dl=0" class="smol">Paper |</a>
          <a href="https://www.dropbox.com/sh/4wcq3vwwgi7gggi/AADKHIRP3O5wsXpSoBpOKwYwa?dl=0" class="smol">Code |</a>
          <a href="https://drive.google.com/drive/folders/11-sAN2a-F7G-lvx6qRXnrWjlxNb0PH1m" class="smol">Data</a>
        </td>
          

      </tr>
  </table>

  
  
      
  


  </a>

  <div align="center">
  <!-- <video height="280" controls> -->
  <!-- <source src="pirl_images/corl.mp4" type="video/mp4"> -->
    <br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/oQjdB2_RlGE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<!-- Your browser does not support the video tag. -->
<!-- </video> -->
</div>

        
  <table style="width:1220px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          
    <h2 align="center">Abstract</h2>

    <p style="line-height:25px;">While  visual  imitation  learning  offers  one  of  themost effective ways of learning from visual demonstrations, gen-eralizing from them requires either hundreds of diverse demon-strations, task specific priors, or large, hard-to-train parametricmodels.  One  reason  such  complexities  arise  is  because  standardvisual  imitation  frameworks  try  to  solve  two  coupled  problemsat  once:  learning  a  succinct  but  good  representation  from  thediverse  visual  data,  while  simultaneously  learning  to  associatethe  demonstrated  actions  with  such  representations.  Such  jointlearning causes an interdependence between these two problems,which  often  results  in  needing  large  amounts  of  demonstrationsfor  learning.  To  address  this  challenge,  we  instead  propose  todecouple   representation   learning   from   behavior   learning   forvisual  imitation.  First,  we  learn  a  visual  representation  encoderfrom  offline  data  using  standard  supervised  and  self-supervisedlearning   methods.   Once   the   representations   are   trained,   weuse  non-parametric  Locally  Weighted  Regression  to  predict  theactions. We experimentally show that this simple decoupling im-proves the performance of visual imitation models on both offlinedemonstration datasets and real-robot door opening compared toprior  work  in  visual  imitation. </p>

    <img src="files/method.png" alt="VINN method">

    <hr>
    <h2 align=center>Demonstrations and Execution</h2>
    <p align=center>These are some examples of how we collected demonstrations and VINN opening various cabinets in 4x speed.</p>

    <table align=center width=540px cellpadding=10 cellspacing=10>
                  <tr>
                    <td align=center width=190px>
                      <center><video height=180px controls>
                      <source src="files/Demo1.mov" type="video/mp4"></center></video></td>
                    <td align=center width=190px>
                      <center><video height=180px controls>
                      <source src="files/linear (1).mp4" type="video/mp4"></center></video></td>
                  <tr/>
                  <tr>
                    <td align=center width=190px>
                      <center><video height=180px controls>
                      <source src="files/VINN1 (1).mov" type="video/mp4"></center></video></td>
                  <td align=center width=190px>
                      <center><video height=180px controls>
                      <source src="files/VINN2.mp4" type="video/mp4"></center></video></td>
                  
                  <tr/>
                 
      </table>

    <hr>
  </tbody></table>

        
      </td>
    </tr>
  </table>
  
</body>

</html>



